Selection Sort =>
                 - NOT STABLE

Bubble Sort => 
                - STABLE
                
Insertion sort => 
            - STABLE (when we are not swapping same values)                

MergeSort => 
            - T(N) = O(N log N) => for best, average and worst case
            - NOT in place (note -> call stack space also being used)
            - It is STABLE


Quick Sort => 
            - T(N) = O(N log N) => for best and average case
              T(N) = O(n^2) => for worst case  (which is very unlikely though => O(log N))
            - IN Place  (note -> call stack space also being used)
            - faster in emprical analysis

Note: Java used QuickSort for primitive types and MergeSort (TimSort) for Objects.


Heap Sort =>   
            reference:  https://reginafurness.medium.com/implementing-a-max-heap-in-javascript-b3e2f788390c

            Time Complexity (Max Heap):

                           leftChild, rightChild, parent, sLeaf() => O(1) 
                           heapifyUp, heapifyDown => O(log n) 
                           add => O(log n)
                           extractMax => O(log n) 
                           print => O(n-l)  l = the number of leaves. In a complete binary tree, 1/2 the nodes are leaves, so you could also say O(1/2n) or simply, O(n).
                           
                           buildHeap => O(n)
                           At the bottom level, the leaves can not be pushed down any further
                           At the second most bottom level, the nodes can at most be pushed down one level
                           At the third most bottom level, the nodes can at most be pushed down two levels
                           As we move up the heap, they can each be pushed down further, but there are less nodes
                           There are more nodes at each level, but the maximum time that heapifyDown can take, 
                           decreases (because as mentioned, heapifyDown actually takes O(h) where h is the height of the heap). So rather than O(n log n), it amounts to O(n).

            Heap Sort
                    reference:  https://reginafurness.medium.com/implementing-heap-sort-in-javascript-e52683b54935
                    
                    To analyze the time complexity of heap sort, we break down each step.

                    1) Turn the array into a max heap (build Heap) => O(N)
                    2) Iterate through the array, on each iteration:
                                a. Swap elements  => O(1)
                                b. Re-heapify the array => O(lon N)

                                So we have => O(n) + O(n * (1 * log n)) => O(N log N)

                    Space complexity => O(1) -> in place
                    Not stable


                    Heap sort isn’t see very often in the real world, but it could be useful for embedded systems where you’re working with little memory, because it takes O(1) space in memory. In addition to that, its best, worst, and average time complexity are all O(n log n), so you don’t run the risk of it taking O(n²) like with quick sort. However, heap sort isn’t as fast as quick sort on large arrays, and offers no advantage when handling partially/mostly sorted arrays. 

Binary Searvh => Time -> O(lon N)
           

        



            
